# -*- coding: utf-8 -*-
"""Untitled33.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hpJijWX5D9_SIYwJNSBnjjEN7eegXfCi
"""

import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
import feedparser
import requests
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import time
import warnings
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
import json
from langdetect import detect
import re
import os
from openai import OpenAI

# Page configuration
st.set_page_config(
    page_title="Xiaomi Stock Sentiment Analysis Platform",
    page_icon="📊",
    layout="wide"
)

# Ignore warnings
warnings.filterwarnings("ignore")

# Sidebar for API key input
with st.sidebar:
    st.title("Configuration")
    openai_api_key = st.text_input("OpenAI API Key", type="password")
    use_huggingface = st.checkbox("Use Hugging Face models (faster but less accurate)", value=True)

    st.markdown("---")
    st.markdown("### Data Settings")
    preferred_language = st.selectbox(
        "Preferred Language",
        ["All Languages", "English", "Chinese", "Spanish"],
        index=0
    )

    preferred_stock = st.selectbox(
        "Preferred Stock Symbol",
        ["1810.HK", "XIACF", "XIACY"],
        index=0
    )

    st.markdown("---")
    st.markdown("### Cache Control")
    if st.button("Clear Cache"):
        st.cache_data.clear()
        st.success("Cache cleared!")

# Initialize OpenAI client if API key is provided
client = None
if openai_api_key:
    os.environ["OPENAI_API_KEY"] = openai_api_key
    client = OpenAI(api_key=openai_api_key)

# Check API validity
def check_api_validity(api_key):
    if not api_key:
        return False

    url = "https://api.openai.com/v1/models"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    try:
        response = requests.get(url, headers=headers)
        return response.status_code == 200
    except:
        return False

# Get multilingual Google News
@st.cache_data(ttl=3600)  # Cache data for 1 hour
def get_google_news_multilang(keyword="Xiaomi", max_articles=100):
    query = keyword.replace(" ", "+")

    # Language settings based on preference
    feeds = []
    if preferred_language == "All Languages" or preferred_language == "Chinese":
        feeds.append({"url": f"https://news.google.com/rss/search?q={query}&hl=zh-CN&gl=CN&ceid=CN:zh-Hans", "language": "zh"})
    if preferred_language == "All Languages" or preferred_language == "English":
        feeds.append({"url": f"https://news.google.com/rss/search?q={query}&hl=en-US&gl=US&ceid=US:en", "language": "en"})
    if preferred_language == "All Languages" or preferred_language == "Spanish":
        feeds.append({"url": f"https://news.google.com/rss/search?q={query}&hl=es-ES&gl=ES&ceid=ES:es", "language": "es"})

    all_entries = []

    for feed_info in feeds:
        try:
            with st.spinner(f"Fetching {feed_info['language']} news..."):
                feed = feedparser.parse(feed_info["url"])
                for entry in feed.entries[:max_articles // len(feeds)]:
                    try:
                        # Handle date parsing
                        try:
                            published_date = datetime(*entry.published_parsed[:6])
                        except:
                            published_date = datetime.now()

                        # Clean HTML tags from titles
                        title = re.sub(r'<[^>]+>', '', entry.title)

                        all_entries.append({
                            "title": title,
                            "link": entry.link,
                            "published": published_date,
                            "language": feed_info["language"]
                        })
                    except Exception as e:
                        st.warning(f"Error parsing entry: {str(e)}")
                        continue
        except Exception as e:
            st.error(f"Error fetching {feed_info['language']} feed: {str(e)}")
            continue

    df = pd.DataFrame(all_entries)

    # Auto-detect language if needed
    if 'title' in df.columns and not df.empty:
        def detect_language(text):
            try:
                return detect(text)
            except:
                return 'unknown'

        # Only use auto-detection when "language" column doesn't exist or is empty
        if 'language' not in df.columns:
            df['language'] = df['title'].apply(detect_language)

    # Sort by publication date
    if not df.empty and 'published' in df.columns:
        df = df.sort_values('published', ascending=False)

    return df

# Get stock data
@st.cache_data(ttl=3600)  # Cache data for 1 hour
def get_xiaomi_stock_data(period="1y"):
    try:
        stock = yf.Ticker(preferred_stock)
        hist_data = stock.history(period=period)

        if hist_data.empty:
            return pd.DataFrame(), "No data available for the selected stock symbol"

        if not isinstance(hist_data.index, pd.DatetimeIndex):
            hist_data.index = pd.to_datetime(hist_data.index)

        # Add technical indicators
        hist_data['MA5'] = hist_data['Close'].rolling(window=5).mean()
        hist_data['MA20'] = hist_data['Close'].rolling(window=20).mean()
        hist_data['Daily_Return'] = hist_data['Close'].pct_change()

        return hist_data, None
    except Exception as e:
        return pd.DataFrame(), f"Failed to fetch stock data: {str(e)}"

# Analyze sentiment
def analyze_sentiment(text, detailed=False):
    if not client and not use_huggingface:
        return None, "OpenAI API key is required for sentiment analysis"

    # Clean text
    cleaned_text = re.sub(r'<[^>]+>', '', text)

    # Auto-detect language
    try:
        lang = detect(cleaned_text)
    except:
        lang = "en"  # Default to English

    # Use OpenAI for sentiment analysis
    try:
        if not detailed:
            # Simplified sentiment analysis
            if client:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "You are a sentiment analysis tool. Analyze the sentiment of the text and respond with only one of these three words: POSITIVE, NEUTRAL, or NEGATIVE."},
                        {"role": "user", "content": f"Analyze the sentiment of this text: {cleaned_text}"}
                    ],
                    max_tokens=10,
                    temperature=0.3
                )
                result = response.choices[0].message.content.strip().upper()
                if "POSITIVE" in result:
                    return 1, None
                elif "NEGATIVE" in result:
                    return -1, None
                else:
                    return 0, None
            else:
                # Simplified sentiment analysis without API
                # This is a very basic implementation
                positive_words = ['good', 'great', 'excellent', 'positive', 'rise', 'up', 'growth', 'profit']
                negative_words = ['bad', 'poor', 'negative', 'down', 'fall', 'decline', 'loss']

                text_lower = cleaned_text.lower()
                pos_count = sum([1 for word in positive_words if word in text_lower])
                neg_count = sum([1 for word in negative_words if word in text_lower])

                if pos_count > neg_count:
                    return 1, None
                elif neg_count > pos_count:
                    return -1, None
                else:
                    return 0, None
        else:
            # Detailed sentiment analysis
            if client:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": """You are a sentiment analysis tool specialized in financial news.
                        Analyze the text sentiment and provide:
                        1. A numeric score from -1 (very negative) to 1 (very positive), using a decimal precision of 0.1
                        2. A brief explanation of the factors contributing to this score
                        Format your response as JSON with keys "score" and "factors"."""},
                        {"role": "user", "content": f"Analyze the sentiment of this financial news text: {cleaned_text}"}
                    ],
                    max_tokens=150,
                    temperature=0.3
                )

                try:
                    result = json.loads(response.choices[0].message.content)
                    return result, None
                except json.JSONDecodeError:
                    content = response.choices[0].message.content
                    score_match = re.search(r'score["\']?\s*:\s*(-?\d+\.\d+|-?\d+)', content)
                    factors_match = re.search(r'factors["\']?\s*:\s*["\']?([^}"\']+)["\']?', content)

                    if score_match:
                        score = float(score_match.group(1))
                        factors = factors_match.group(1) if factors_match else "No explanation provided"
                        return {"score": score, "factors": factors}, None
                    else:
                        return {"score": 0, "factors": "Failed to parse response"}, None
            else:
                # Simplified detailed analysis without API
                positive_words = ['good', 'great', 'excellent', 'positive', 'rise', 'up', 'growth', 'profit']
                negative_words = ['bad', 'poor', 'negative', 'down', 'fall', 'decline', 'loss']

                text_lower = cleaned_text.lower()
                pos_count = sum([1 for word in positive_words if word in text_lower])
                neg_count = sum([1 for word in negative_words if word in text_lower])

                total = pos_count + neg_count
                if total == 0:
                    score = 0
                    factors = "No sentiment indicators found in text"
                else:
                    score = (pos_count - neg_count) / (pos_count + neg_count)
                    if score > 0:
                        factors = f"Found positive indicators: {pos_count} positive words vs {neg_count} negative words"
                    elif score < 0:
                        factors = f"Found negative indicators: {neg_count} negative words vs {pos_count} positive words"
                    else:
                        factors = f"Equal positive and negative indicators: {pos_count} each"

                return {"score": score, "factors": factors}, None

    except Exception as e:
        return None, f"Sentiment analysis failed: {str(e)}"

# Predict stock trend
def predict_stock_trend(stock_data, days_ahead=7):
    if stock_data.empty or 'Close' not in stock_data.columns:
        return None, "No stock data available for prediction"

    try:
        # Copy data to avoid modifying original
        df = stock_data.copy()

        # Ensure index is datetime type
        if not isinstance(df.index, pd.DatetimeIndex):
            df.index = pd.to_datetime(df.index)

        # Feature engineering: Add date features
        df['day_of_week'] = df.index.dayofweek
        df['month'] = df.index.month

        # Prepare training data
        X = df[['day_of_week', 'month']].values
        y = df['Close'].values

        # Use polynomial regression
        poly = PolynomialFeatures(degree=2)
        X_poly = poly.fit_transform(X)

        model = LinearRegression()
        model.fit(X_poly, y)

        # Generate prediction dates
        last_date = df.index[-1]
        future_dates = [last_date + timedelta(days=i+1) for i in range(days_ahead)]

        # Prepare prediction features
        future_features = [[date.dayofweek, date.month] for date in future_dates]
        future_features_poly = poly.transform(future_features)

        # Predict
        predictions = model.predict(future_features_poly)

        # Create prediction dataframe
        prediction_df = pd.DataFrame({
            'Date': future_dates,
            'Predicted_Close': predictions
        }).set_index('Date')

        return prediction_df, None

    except Exception as e:
        return None, f"Prediction failed: {str(e)}"

# Batch sentiment analysis
def batch_sentiment_analysis(df, count=10):
    if df.empty or 'title' not in df.columns:
        return pd.DataFrame(), "No data available for analysis"

    # Ensure not to exceed available data
    count = min(count, len(df))
    df_subset = df.head(count).copy()

    results = []

    # Create progress bar
    progress_bar = st.progress(0)

    for i, row in enumerate(df_subset.itertuples()):
        try:
            text = row.title

            # Use simplified analysis for speed
            simple_score, error = analyze_sentiment(text, detailed=False)

            if error:
                st.warning(f"Simple analysis failed: {error}")
                simple_label = "Neutral"
            else:
                simple_label = "Positive" if simple_score > 0 else ("Negative" if simple_score < 0 else "Neutral")

            # Perform detailed analysis for non-neutral results
            if simple_label != "Neutral":
                detailed_result, error = analyze_sentiment(text, detailed=True)

                if error:
                    st.warning(f"Detailed analysis failed: {error}")
                    score = simple_score  # Fall back to simple score
                    factors = "No detailed analysis available"
                else:
                    score = detailed_result["score"]
                    factors = detailed_result["factors"]
            else:
                # No need for detailed analysis on neutral results
                score = 0
                factors = "Neutral sentiment"

            # Ensure 'time' field exists
            if hasattr(row, 'published'):
                time_value = row.published
            else:
                time_value = datetime.now()

            # Add language info
            language = row.language if hasattr(row, 'language') else 'unknown'

            results.append({
                "title": text,
                "score": score,
                "label": "Positive" if score > 0.3 else "Negative" if score < -0.3 else "Neutral",
                "factors": factors,
                "time": time_value,
                "language": language
            })

            # Update progress bar
            progress_bar.progress((i + 1) / count)

            # Add delay to prevent API rate limiting
            time.sleep(0.5)

        except Exception as e:
            st.error(f"Error analyzing article: {str(e)}")

    progress_bar.empty()

    return pd.DataFrame(results), None

# Main app structure with tabs
tab1, tab2, tab3, tab4, tab5 = st.tabs(["📰 News Display", "💹 Stock Data", "🧠 Sentiment Analysis", "📊 Visualization", "📈 Predictions"])

# Tab 1: News Display
with tab1:
    st.header("Xiaomi News Feed")

    col1, col2, col3 = st.columns([2, 1, 1])
    with col1:
        topic = st.selectbox(
            "Topic",
            ["Xiaomi", "Xiaomi smartphone", "Xiaomi financial", "Xiaomi earnings"],
            index=0
        )
    with col2:
        limit = st.selectbox(
            "Limit",
            [50, 100, 200, 300],
            index=1
        )
    with col3:
        if st.button("Refresh News", type="primary"):
            st.session_state.news_df = get_google_news_multilang(topic, limit)

    # Display news
    if 'news_df' not in st.session_state:
        st.session_state.news_df = get_google_news_multilang(topic, limit)

    news_df = st.session_state.news_df

    if news_df.empty:
        st.error("No news found. Please try again.")
    else:
        st.success(f"Successfully fetched {len(news_df)} news articles")

        # Display language distribution
        if 'language' in news_df.columns:
            lang_counts = news_df['language'].value_counts()

            # Create columns for distribution chart and data
            col1, col2 = st.columns([1, 2])

            with col1:
                st.subheader("Language Distribution")
                fig, ax = plt.subplots(figsize=(5, 5))
                ax.pie(
                    lang_counts.values,
                    labels=lang_counts.index,
                    autopct='%1.1f%%',
                    startangle=90
                )
                ax.axis('equal')
                st.pyplot(fig)

            with col2:
                st.subheader("Most Recent News")
                st.dataframe(
                    news_df[['published', 'language', 'title']].head(10),
                    use_container_width=True,
                    column_config={
                        "published": st.column_config.DatetimeColumn("Published", format="D MMM YYYY, HH:mm"),
                        "language": st.column_config.TextColumn("Language"),
                        "title": st.column_config.TextColumn("Title")
                    }
                )

        # Display all news with pagination
        st.subheader("All News Articles")
        page_size = 20
        total_pages = (len(news_df) + page_size - 1) // page_size

        col1, col2 = st.columns([4, 1])
        with col2:
            page = st.selectbox("Page", range(1, total_pages + 1))

        start_idx = (page - 1) * page_size
        end_idx = min(start_idx + page_size, len(news_df))

        st.dataframe(
            news_df.iloc[start_idx:end_idx][['published', 'language', 'title', 'link']],
            use_container_width=True,
            column_config={
                "published": st.column_config.DatetimeColumn("Published", format="D MMM YYYY, HH:mm"),
                "language": st.column_config.TextColumn("Language"),
                "title": st.column_config.TextColumn("Title"),
                "link": st.column_config.LinkColumn("Link")
            }
        )

# Tab 2: Stock Data
with tab2:
    st.header("Xiaomi Stock Data")

    col1, col2 = st.columns([3, 1])
    with col1:
        period = st.selectbox(
            "Period",
            [("1 Week", "1wk"), ("1 Month", "1mo"), ("3 Months", "3mo"),
             ("6 Months", "6mo"), ("1 Year", "1y"), ("5 Years", "5y")],
            format_func=lambda x: x[0],
            index=4
        )
    with col2:
        if st.button("Fetch Data", type="primary"):
            st.session_state.stock_df, error = get_xiaomi_stock_data(period[1])
            if error:
                st.error(error)

    # Display stock data
    if 'stock_df' not in st.session_state:
        st.session_state.stock_df, error = get_xiaomi_stock_data(period[1])
        if error:
            st.error(error)

    stock_df = st.session_state.stock_df

    if stock_df.empty:
        st.error("No stock data available.")
    else:
        # Display basic statistics
        st.subheader("Basic Statistics")

        latest_price = stock_df['Close'].iloc[-1]
        start_price = stock_df['Close'].iloc[0]
        price_change = latest_price - start_price
        price_change_pct = (price_change / start_price) * 100

        col1, col2, col3, col4 = st.columns(4)
        col1.metric("Starting Price", f"{start_price:.2f}")
        col2.metric("Latest Price", f"{latest_price:.2f}", f"{price_change:.2f} ({price_change_pct:.2f}%)")
        col3.metric("Highest Price", f"{stock_df['High'].max():.2f}")
        col4.metric("Lowest Price", f"{stock_df['Low'].min():.2f}")

        # Stock chart
        st.subheader("Stock Price Chart")

        # Create a two-row chart with price and volume
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8), gridspec_kw={'height_ratios': [3, 1]}, sharex=True)

        # Plot close price
        ax1.plot(stock_df.index, stock_df['Close'], 'b-', label='Close Price', linewidth=1.5)

        # Add moving averages
        if 'MA5' in stock_df.columns:
            ax1.plot(stock_df.index, stock_df['MA5'], 'orange', label='5-Day MA', linewidth=1)
        if 'MA20' in stock_df.columns:
            ax1.plot(stock_df.index, stock_df['MA20'], 'g-', label='20-Day MA', linewidth=1)

        # Set upper chart title and labels
        ax1.set_title('Xiaomi Stock Price')
        ax1.set_ylabel('Price (HKD)')
        ax1.grid(True, alpha=0.3)
        ax1.legend(loc='best')

        # Highlight latest price
        ax1.plot(stock_df.index[-1], latest_price, 'ro', markersize=8)
        ax1.annotate(
            f'¥{latest_price:.2f}',
            xy=(stock_df.index[-1], latest_price),
            xytext=(15, 0),
            textcoords='offset points',
            fontweight='bold',
            color='red'
        )

        # Plot volume bars
        volume_colors = ['red' if stock_df['Open'].iloc[i] > stock_df['Close'].iloc[i] else 'green'
                        for i in range(len(stock_df))]
        ax2.bar(stock_df.index, stock_df['Volume'], color=volume_colors, alpha=0.7)
        ax2.set_ylabel('Volume')
        ax2.grid(True, alpha=0.3)

        # Format date axis
        fig.autofmt_xdate()

        plt.tight_layout()
        st.pyplot(fig)

        # Display latest trading data
        st.subheader("Latest Trading Data")
        st.dataframe(
            stock_df.tail(5)[['Open', 'High', 'Low', 'Close', 'Volume']],
            use_container_width=True
        )

# Tab 3: Sentiment Analysis
with tab3:
    st.header("Sentiment Analysis")

    # Check if news data is available
    if 'news_df' not in st.session_state or st.session_state.news_df.empty:
        st.warning("Please fetch news data first in the News Display tab.")
    else:
        news_df = st.session_state.news_df

        # Select news for analysis
        selected_news = st.selectbox(
            "Select News Article for Analysis",
            options=range(len(news_df)),
            format_func=lambda i: f"[{news_df.iloc[i]['language']}] {news_df.iloc[i]['title'][:80]}..."
        )

        if st.button("Analyze Sentiment", type="primary"):
            with st.spinner("Analyzing sentiment..."):
                text = news_df.iloc[selected_news]["title"]
                st.write(f"Analyzing: **{text}**")

                # Get detailed sentiment analysis
                result, error = analyze_sentiment(text, detailed=True)

                if error:
                    st.error(f"Error: {error}")
                else:
                    score = result["score"]
                    factors = result["factors"]

                    # Determine sentiment label and color
                    if score > 0.3:
                        label = "Positive"
                        color = "green"
                    elif score < -0.3:
                        label = "Negative"
                        color = "red"
                    else:
                        label = "Neutral"
                        color = "gray"

                    # Display results
                    st.markdown(f"### Sentiment: <span style='color:{color}'>{label}</span>", unsafe_allow_html=True)
                    st.markdown(f"**Score:** {score:.2f} (range: -1 to 1)")
                    st.markdown(f"**Key factors:** {factors}")

                    # Create visualization
                    fig, ax = plt.subplots(figsize=(8, 2))

                    # Create sentiment bar
                    cmap = plt.cm.RdYlGn  # Red-Yellow-Green colormap
                    norm_score = (score + 1) / 2  # Normalize to 0-1 range

                    ax.barh(['Sentiment'], [score], color=cmap(norm_score))
                    ax.axvline(x=0, color='gray', linestyle='-', alpha=0.3)
                    ax.set_xlim(-1, 1)
                    ax.set_xticks([-1, -0.5, 0, 0.5, 1])
                    ax.set_xticklabels(['Very Negative', 'Negative', 'Neutral', 'Positive', 'Very Positive'])
                    ax.set_title('Sentiment Score Visualization')
                    plt.tight_layout()
                    st.pyplot(fig)

# Tab 4: Visualization
with tab4:
    st.header("Batch Sentiment Analysis and Visualization")

    # Check if news data is available
    if 'news_df' not in st.session_state or st.session_state.news_df.empty:
        st.warning("Please fetch news data first in the News Display tab.")
    else:
        news_df = st.session_state.news_df

        col1, col2, col3 = st.columns([2, 1, 1])
        with col1:
            source = st.selectbox(
                "Source",
                ["Current News"],
                index=0
            )
        with col2:
            count = st.slider("Number of Articles", 5, 50, 10, 5)
        with col3:
            if st.button("Run Analysis", type="primary"):
                with st.spinner("Analyzing articles..."):
                    st.session_state.sentiment_df, error = batch_sentiment_analysis(news_df, count)
                    if error:
                        st.error(error)

        # Display results if available
        if 'sentiment_df' not in st.session_state:
            st.info("Click 'Run Analysis' to start batch sentiment analysis.")
        elif st.session_state.sentiment_df.empty:
            st.error("No articles were successfully analyzed.")
        else:
            sentiment_df = st.session_state.sentiment_df

            # Calculate sentiment distribution
            positive = (sentiment_df['score'] > 0.3).sum()
            negative = (sentiment_df['score'] < -0.3).sum()
            neutral = len(sentiment_df) - positive - negative
            avg_score = sentiment_df['score'].mean()

            st.success(f"Analysis complete with average sentiment score: {avg_score:.2f}")

            # Create two columns for charts
            col1, col2 = st.columns(2)

            # Pie chart in first column
            with col1:
                st.subheader("Sentiment Distribution")
                fig, ax = plt.subplots(figsize=(6, 6))
                ax.pie(
                    [positive, neutral, negative],
                    labels=['Positive', 'Neutral', 'Negative'],
                    colors=['green', 'gray', 'red'],
                    autopct='%1.1f%%',
                    explode=(0.1, 0, 0),
                    startangle=90
                )
                ax.axis('equal')
                st.pyplot(fig)

            # Histogram in second column
            with col2:
                st.subheader("Sentiment Score Distribution")
                fig, ax = plt.subplots(figsize=(6, 6))
                ax.hist(sentiment_df['score'], bins=10, color='skyblue', edgecolor='black')
                ax.axvline(avg_score, color='red', linestyle='--', label=f'Average: {avg_score:.2f}')
                ax.set_xlabel("Score")
                ax.set_ylabel("Frequency")
                ax.legend()
                st.pyplot(fig)

            # Time trend chart if time data is available
            if 'time' in sentiment_df.columns:
                st.subheader("Sentiment Trend Over Time")

                # Ensure time column is datetime
                if not pd.api.types.is_datetime64_any_dtype(sentiment_df['time']):
                    sentiment_df['time'] = pd.to_datetime(sentiment_df['time'])

                # Sort by time
                time_sorted_df = sentiment_df.sort_values('time')

                fig, ax = plt.subplots(figsize=(10, 6))

                # Create scatter plot with color mapping to sentiment values
                scatter = ax.scatter(
                    time_sorted_df['time'],
                    time_sorted_df['score'],
                    c=time_sorted_df['score'],
                    cmap='RdYlGn',
                    s=100,
                    alpha=0.7
                )

                # Add connection lines
                ax.plot(time_sorted_df['time'], time_sorted_df['score'], 'k-', alpha=0.3)

                # Add horizontal zero line
                ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)

                # Add colorbar
                cbar = plt.colorbar(scatter, ax=ax)
                cbar.set_label('Sentiment Score')

                ax.set_title('Sentiment Trend Over Time')
                ax.set_xlabel('Date')
                ax.set_ylabel('Sentiment Score')
                fig.autofmt_xdate()
                plt.tight_layout()
                st.pyplot(fig)

            # Language distribution if language data is available
            if 'language' in sentiment_df.columns:
                st.subheader("Average Sentiment by Language")
                lang_groups = sentiment_df.groupby('language')['score'].agg(['mean', 'count'])

                fig, ax = plt.subplots(figsize=(8, 6))
                bars = ax.bar(
                    lang_groups.index,
                    lang_groups['mean'],
                    color=['green' if x > 0.3 else 'red' if x < -0.3 else 'gray' for x in lang_groups['mean']]
                )

                # Add data labels
                for i, bar in enumerate(bars):
                    height = bar.get_height()
                    ax.text(
                        bar.get_x() + bar.get_width()/2.,
                        height,
                        f'n={lang_groups.iloc[i]["count"]}',
                        ha='center', va='bottom' if height > 0 else 'top'
                    )

                # Add horizontal zero line
                ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)

                ax.set_title('Average Sentiment by Language')
                ax.set_xlabel('Language')
                ax.set_ylabel('Average Sentiment Score')
                plt.tight_layout()
                st.pyplot(fig)

            # Display detailed results table
            st.subheader("Detailed Sentiment Results")
            st.dataframe(
                sentiment_df[['time', 'language', 'title', 'score', 'label', 'factors']],
                use_container_width=True,
                column_config={
                    "time": st.column_config.DatetimeColumn("Time", format="D MMM YYYY, HH:mm"),
                    "language": st.column_config.TextColumn("Language"),
                    "title": st.column_config.TextColumn("Title"),
                    "score": st.column_config.NumberColumn("Score", format="%.2f"),
                    "label": st.column_config.TextColumn("Label"),
                    "factors": st.column_config.TextColumn("Factors")
                }
            )

            # Download link for CSV export
            csv = sentiment_df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="Download CSV",
                data=csv,
                file_name=f"sentiment_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
            )

# Tab 5: Predictions
with tab5:
    st.header("Stock Price Predictions")

    # Check if stock data is available
    if 'stock_df' not in st.session_state or st.session_state.stock_df.empty:
        st.warning("Please fetch stock data first in the Stock Data tab.")
    else:
        stock_df = st.session_state.stock_df

        # Forecast settings
        forecast_days = st.selectbox(
            "Forecast Period",
            [7, 14, 30],
            index=0,
            format_func=lambda x: f"{x} days"
        )

        if st.button("Generate Prediction", type="primary"):
            with st.spinner("Generating forecast..."):
                prediction_df, error = predict_stock_trend(stock_df, forecast_days)
                st.session_state.prediction_df = prediction_df
                st.session_state.prediction_error = error

        # Display prediction results
        if 'prediction_df' not in st.session_state:
            st.info("Click 'Generate Prediction' to start stock price forecast.")
        elif st.session_state.prediction_error:
            st.error(st.session_state.prediction_error)
        else:
            prediction_df = st.session_state.prediction_df

            if prediction_df.empty:
                st.error("Failed to generate prediction.")
            else:
                st.success(f"Successfully generated {forecast_days}-day prediction")

                # Display prediction table
                st.subheader("Prediction Results")
                st.dataframe(
                    prediction_df,
                    use_container_width=True,
                    column_config={
                        "Predicted_Close": st.column_config.NumberColumn("Predicted Close", format="%.2f")
                    }
                )

                # Plot historical data and prediction
                st.subheader("Stock Price Forecast")

                fig, ax = plt.subplots(figsize=(12, 8))

                # Plot historical price
                ax.plot(
                    stock_df.index,
                    stock_df['Close'],
                    'b-',
                    label='Historical',
                    linewidth=2
                )

                # Plot prediction
                ax.plot(
                    prediction_df.index,
                    prediction_df['Predicted_Close'],
                    'r--',
                    marker='o',
                    markersize=6,
                    label='Prediction',
                    linewidth=2
                )

                # Add vertical line marking prediction start
                last_date = stock_df.index[-1]
                ax.axvline(x=last_date, color='green', linestyle=':', alpha=0.7)

                # Add annotation
                ax.annotate(
                    'Prediction Start',
                    xy=(last_date, stock_df['Close'].iloc[-1]),
                    xytext=(15, 15),
                    textcoords='offset points',
                    arrowprops=dict(arrowstyle='->', color='green'),
                    fontsize=12
                )

                ax.set_title('Xiaomi Stock Price Forecast', fontsize=16)
                ax.set_xlabel('Date', fontsize=12)
                ax.set_ylabel('Price (HKD)', fontsize=12)
                ax.legend(fontsize=12)
                ax.grid(True, alpha=0.3)
                fig.autofmt_xdate()
                plt.tight_layout()
                st.pyplot(fig)

                # Analyze prediction trend
                first_price = prediction_df['Predicted_Close'].iloc[0]
                last_price = prediction_df['Predicted_Close'].iloc[-1]
                price_change = last_price - first_price
                price_change_pct = (price_change / first_price) * 100

                if price_change > 0:
                    trend = "upward"
                    trend_color = "green"
                elif price_change < 0:
                    trend = "downward"
                    trend_color = "red"
                else:
                    trend = "stable"
                    trend_color = "gray"

                # Display trend analysis
                st.subheader("Prediction Trend Analysis")
                st.markdown(f"The prediction shows an <span style='color:{trend_color};font-weight:bold;'>{trend}</span> trend over the next {forecast_days} days.", unsafe_allow_html=True)

                col1, col2, col3 = st.columns(3)
                col1.metric("Predicted Change", f"{price_change:.2f}", f"{price_change_pct:.2f}%")
                col2.metric("Starting Price", f"{first_price:.2f}")
                col3.metric("Ending Price", f"{last_price:.2f}")

                # Correlation with sentiment if available
                if 'sentiment_df' in st.session_state and not st.session_state.sentiment_df.empty:
                    sentiment_df = st.session_state.sentiment_df
                    avg_sentiment = sentiment_df['score'].mean()

                    st.subheader("Sentiment Correlation")
                    st.write(f"Average news sentiment score: {avg_sentiment:.2f}")

                    if (avg_sentiment > 0.2 and price_change > 0) or (avg_sentiment < -0.2 and price_change < 0):
                        st.success("✅ Sentiment analysis and price prediction trend are aligned")
                    else:
                        st.warning("⚠️ Sentiment analysis and price prediction trend may not be aligned")

# Footer
st.markdown("---")
st.markdown("Xiaomi Stock Sentiment Analysis Platform v2.0 | Developed with Streamlit")

# Initial API check message
if not client:
    st.sidebar.warning("⚠️ OpenAI API Key not provided. Some features will have limited functionality.")
elif not check_api_validity(openai_api_key):
    st.sidebar.error("❌ Invalid OpenAI API Key. Please check and update.")
else:
    st.sidebar.success("✅ OpenAI API is operational!")